---
layout: distill
title: MixNAR
description: A blogpost about neural algorithmic reasoning, modularity (mixture of experts) and how trying to implement the first modular reasoner gave insights about one of the most difficult algorithms to emulate. *TODO*
date: 2025-04-28
future: true
htmlwidgets: true
hidden: false

# Anonymize when submitting
# authors:
#   - name: Anonymous

authors:
  - name: Anonymous

#  - name: Albert Einstein
#    url: "https://en.wikipedia.org/wiki/Albert_Einstein"
#    affiliations:
#      name: IAS, Princeton
#  - name: Boris Podolsky
#    url: "https://en.wikipedia.org/wiki/Boris_Podolsky"
#    affiliations:
#      name: IAS, Princeton
#  - name: Nathan Rosen
#    url: "https://en.wikipedia.org/wiki/Nathan_Rosen"
#    affiliations:
#      name: IAS, Princeton

# must be the exact same name as your blogpost
bibliography: 2025-04-28-modnar.bib  

# Add a table of contents to your post.
#   - make sure that TOC names match the actual section names
#     for hyperlinks within the post to work correctly. 
#   - please use this format rather than manually creating a markdown table of contents.
toc:
  - name: Before we start
  - name: NAR-101
    subsections:
    - name: Alignment
    - name: The CLRS-30 benchmark
    - name: Current SOTAs
  - name: Citations
  - name: Footnotes
  - name: Code Blocks
  - name: Diagrams
  - name: Tweets
  - name: Layouts
  - name: Other Typography?


---

## Before we start

To save the reader their time, I will begin my writings by making clear one
important thing. _This is a blogpost and it will read as such._ Therefore it
will not follow a traditional paper structure.<d-footnote> Starts with
introduction complemented with 3+ contributions, followed by related work,
methodology, experiments, conclusions.</d-footnote> Instead, I decided to lay
out my train of thought in a way that would be interesting from the perspective
of an NAR expert, but also from the perspective of an early career researcher
who would like to glimpse how a (self-proclaimed) NAR researcher thinks like.

However, I do understand that some might be newcomers to the topic. Therefore,
I would like to start this blogpost with...

## NAR-101

Consider how a programmer may solve a problem: They
would check what instruments they have in their toolkit -- books such
as _Introduction to Algorithms_ <d-cite key="clrs"></d-cite> (a.k.a. CLRS) or _Algorithms_ <d-cite
key="sedgewick2011algorithms"></d-cite>, choose the most suitable out of the
set and start matching the problem to the tool. Manually performing the last
part may involve rethinking the problem at hand, consulting their teammates or
_performing various forms of witchcraft_, such as plugging random pieces of
data or scalar functions of them as the input to the algorithm and seeing what
happens.  It is conjectured that this gap between theoretical algorithms and
their real-life execution largely stems from the _scalar bottleneck_ --
having to represent multitude of factors with a single scalar. <d-cite
key="narblueprint"></d-cite>

**N**eural **a**lgorithmic **r**easoning (**NAR**) focuses on training graph neural
networks (**GNNs**) to execute algorithms in a vectorial latent space<d-footnote>i.e.,
node features are 64-dimensional vectors</d-footnote> so we can overcome the
scalar bottleneck. When deploying an algorithm of interest to a problem we can
leave it to gradient descent instead of the programmer to find an appropriate
mapping. <d-cite key="deac2020xlvin"></d-cite><d-cite
key="tang2020towards"></d-cite><d-cite
key="he2022continuous"></d-cite><d-cite
key="numeroso2023dar"></d-cite><d-cite key="panagiotaki2024naricp"></d-cite>

### Alignment 

Even from the earliest papers on NAR <d-cite
key="velickovic2020neural"></d-cite> it became obvious that training a robust
neural reasoner, _that can give correct outputs for inputs of any (even larger
ones than trained on) sizes_ is not an easy task. It requires _architectural
alignment_. Giving a precise definition is a lengthy task for a blogpost, but
some intuition never hurts:


{% include figure.html path="assets/img/2025-04-28-modnar/alignment.png" class="alignment" %}
<div class="caption">
    Figure source: Veliƒçkoviƒá <d-cite key="velickovic2023nargradient"></d-cite>
</div>

<blockquote>
    Neural networks extrapolate well if the algorithm can be separated into subfunctions and each of them is easily learnable by a corresponding neural submodule.
    - The core idea of Xu et al. <d-cite key="xu2020howneural"></d-cite>
</blockquote>

Or in other words, GNNs extrapolate very easily on the Bellman-Ford algorithm,
because:
- the intermediate algorithm values correspond to the latent features of the
  nodes
- the multi-layer perceptron (**MLP**) that computes the messages can easily
  learn linear functions like addition
- we can choose the GNN neighbourhood aggregation to match the operator
  ($\min$) of the algorithm

This is just a simplified example and aligning neural models with other
algorithmic properties is an active (and tough) area of research. As I will
strive to keep the 101 just as much as you would need to understand **this**
blogpost, I refer the enthusiastic reader to another one <d-cite
key="velickovic2023nargradient"></d-cite> for more details and papers on NAR
alignment.

### The CLRS-30 Benchmark

The CLRS-30 benchmark <d-cite key="velivckovic2022clrs"></d-cite> includes more
than just 30 instances from the _Introduction to Algorithms_ textbook. It
provides a unifying framework for representing algorithmic problems to the
GNNs. Getting familiar with the API/pipeline requires some time to master, so
if you are looking for where to start from, [this EEML 2024 tutorial][eeml2024]
is a good place to start

[eeml2024]: https://github.com/eemlcommunity/PracticalSessions2024/blob/main/1_reasoning/Reasoning_tutorial_solution.ipynb

However, I believe having a good grasp of the CLRS-30 lingo is sufficient for
understanding **this** blogpost and does not require us studying all the
codebase. We can get to the required level of knowledge, again, through
examples.


To start with, at a given timestep, all information about an algorithm is
stored as a set of `(Stage, Location, Datatype)` triplets.

{% highlight python linenos %}

class Stage:
  INPUT = 'input'
  OUTPUT = 'output'
  HINT = 'hint'

class Location:
  NODE = 'node'
  EDGE = 'edge'
  GRAPH = 'graph'

class Type:
  SCALAR = 'scalar'
  CATEGORICAL = 'categorical' # for variables with categorical featues
  MASK = 'mask' # binary features
  MASK_ONE = 'mask_one' # same as MASK, just one element is allowed to be 1
  # Make no mistake -- mask_one is still a binary, not a categorical feature
  POINTER = 'pointer'
  # ... some types omitted for brevity ...

{% endhighlight %}

`Location` (notion for node/edge/graph features), as well as the `Stage.INPUT`
and `Stage.OUTPUT` are self-explanatory. `Stage.HINT` is CLRS-specific and it
allows for modelling the trajectory of the algorithm -- at any timestep $\tau$
the NAR would take as input hints computed from the previous step $\tau-1$ and
learn to predict what the hints are for step $\tau$. `Type` dictates how
features should be processed, including what losses should we use for training.
Of all types, the only non-trivial one is `Type.POINTER`. E.g. the node pointer
for node $i$ behaves like an edge (yes, it is not a typo) from $i$ to any other
node $j$, with the restriction that there could be only **one** pointer from
node $i$.<d-footnote>Some NAR development frameworks, such as the one I used
here, put an even harder restriction that a pointer must be an edge in the
graph. This is usually done to maintain low memory usage -- $O(E)$ instead of
$O(V^2)$. For this project, however, $E=V^2$, so we did not get the
benefits... but I have a preference for PyTorch over JAX</d-footnote>

How all the data for an algorithm looks like is described via specifications,
like the one below, corresponding to the Bellman-Ford algorithm.<d-footnote>If
the names of the variables are too cryptic for your taste, a pro advice from me
is to check the _Introduction to Algorithms_. The authors of the CLRS benchmark
usually use the same variable names.</d-footnote>

{% highlight python linenos %}

SPECS = types.MappingProxyType({
    # ... many algorithms omitted for brevity ...
    'bellman_ford': {
        # just a tie-breaker, in case two solutions are identical
        'pos': (Stage.INPUT, Location.NODE, Type.SCALAR),
        # starting node
        's': (Stage.INPUT, Location.NODE, Type.MASK_ONE),
        # weight matrix (NxN)
        'A': (Stage.INPUT, Location.EDGE, Type.SCALAR),
        # adjacency matrix
        'adj': (Stage.INPUT, Location.EDGE, Type.MASK),
        # predecessors array pi[i] holds the id of the
        # tip of the pointer from i
        'pi': (Stage.OUTPUT, Location.NODE, Type.POINTER),
        # same as above, but for each timestep of algorithm's execution;
        # the default starting pi array consists of self-loops (pi[i]=i) 
        'pi_h': (Stage.HINT, Location.NODE, Type.POINTER),
        # shortest distances at a given timestep
        'd': (Stage.HINT, Location.NODE, Type.SCALAR),
        # reachable nodes at a given timestep
        'msk': (Stage.HINT, Location.NODE, Type.MASK),
    },
    # ... many algorithms omitted for brevity ...
})

{% endhighlight %}

This should be all you need to know... for now.


#### Current SOTAs

As you can see from the year of publication, this benchmark has been around for
a while. A lot of research has went into creating models that improve on
previous ones and so on and so forth. As a result, only for all but three (out
of thirty) algorithms no one has reported OOD accuracy above 80%. <d-cite
key="xu2024recurrent"></d-cite> The most challenging of the trio and the one
I tried to tackle is...


# üõ°Ô∏èüó°Ô∏è Knuth-Morris-Pratt

{% include figure.html path="assets/img/2025-04-28-modnar/darksouls.png"  class="img-fluid" %}
